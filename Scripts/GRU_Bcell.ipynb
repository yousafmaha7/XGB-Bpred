{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d51f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace this with your desired path\n",
    "os.chdir(\"D:XGB_DS\")\n",
    "\n",
    "# Optional: confirm change\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from collections import Counter\n",
    "from tensorflow.keras.layers import Input, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "train_data = pd.read_csv(\"train_B_data.csv\")\n",
    "test_data = pd.read_csv(\"test_B_data.csv\")\n",
    "eval_data = pd.read_csv(\"external_eval_B_data.csv\")\n",
    "\n",
    "X_seq_train_raw = train_data['Epitopes'].tolist()\n",
    "X_seq_test_raw = test_data['Epitopes'].tolist()\n",
    "X_seq_eval_raw = eval_data['Epitopes'].tolist()\n",
    "\n",
    "y_train = train_data['Label'].values\n",
    "y_test = test_data['Label'].values\n",
    "y_eval = eval_data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87fdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Original label distribution in train data:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ba871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Define Blosum62 Matrix ===\n",
    "blosum62 = {\n",
    "    'A':[4,-1,-2,-2,0,-1,-1,0,-2,-1,-1,-1,-1,-2,-1,1,0,-3,-2,0],\n",
    "    'R':[-1,5,0,-2,-3,1,0,-2,0,-3,-2,2,-1,-3,-2,-1,-1,-3,-2,-3],\n",
    "    'N':[-2,0,6,1,-3,0,0,0,1,-3,-3,0,-2,-3,-2,1,0,-4,-2,-3],\n",
    "    'D':[-2,-2,1,6,-3,0,2,-1,-1,-3,-4,-1,-3,-3,-1,0,-1,-4,-3,-3],\n",
    "    'C':[0,-3,-3,-3,9,-3,-4,-3,-3,-1,-1,-3,-1,-2,-3,-1,-1,-2,-2,-1],\n",
    "    'Q':[-1,1,0,0,-3,5,2,-2,0,-3,-2,1,0,-3,-1,0,-1,-2,-1,-2],\n",
    "    'E':[-1,0,0,2,-4,2,5,-2,0,-3,-3,1,-2,-3,-1,0,-1,-3,-2,-2],\n",
    "    'G':[0,-2,0,-1,-3,-2,-2,6,-2,-4,-4,-2,-3,-3,-2,0,-2,-2,-3,-3],\n",
    "    'H':[-2,0,1,-1,-3,0,0,-2,8,-3,-3,-1,-2,-1,-2,-1,-2,-2,2,-3],\n",
    "    'I':[-1,-3,-3,-3,-1,-3,-3,-4,-3,4,2,-3,1,0,-3,-2,-1,-3,-1,3],\n",
    "    'L':[-1,-2,-3,-4,-1,-2,-3,-4,-3,2,4,-2,2,0,-3,-2,-1,-2,-1,1],\n",
    "    'K':[-1,2,0,-1,-3,1,1,-2,-1,-3,-2,5,-1,-3,-1,0,-1,-3,-2,-2],\n",
    "    'M':[-1,-1,-2,-3,-1,0,-2,-3,-2,1,2,-1,5,0,-2,-1,-1,-1,-1,1],\n",
    "    'F':[-2,-3,-3,-3,-2,-3,-3,-3,-1,0,0,-3,0,6,-4,-2,-2,1,3,-1],\n",
    "    'P':[-1,-2,-2,-1,-3,-1,-1,-2,-2,-3,-3,-1,-2,-4,7,-1,-1,-4,-3,-2],\n",
    "    'S':[1,-1,1,0,-1,0,0,0,-1,-2,-2,0,-1,-2,-1,4,1,-3,-2,-2],\n",
    "    'T':[0,-1,0,-1,-1,-1,-1,-2,-2,-1,-1,-1,-1,-2,-1,1,5,-2,-2,0],\n",
    "    'W':[-3,-3,-4,-4,-2,-2,-3,-2,-2,-3,-2,-3,-1,1,-4,-3,-2,11,2,-3],\n",
    "    'Y':[-2,-2,-2,-3,-2,-1,-2,-3,2,-1,-1,-2,-1,3,-3,-2,-2,2,7,-1],\n",
    "    'V':[0,-3,-3,-3,-1,-2,-2,-3,-3,3,1,-2,1,-1,-2,-2,0,-3,-1,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e860d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute length of each epitope in the training set\n",
    "epitope_lengths = [len(seq) for seq in X_seq_train_raw]\n",
    "\n",
    "# Get the maximum length\n",
    "max_length = max(epitope_lengths)\n",
    "\n",
    "print(\"Maximum epitope length in training data:\", max_length)\n",
    "\n",
    "# Compute maximum epitope length in test data\n",
    "test_lengths = [len(seq) for seq in X_seq_test_raw]\n",
    "max_test_len = max(test_lengths)\n",
    "print(\"Maximum epitope length in test data:\", max_test_len)\n",
    "\n",
    "# Compute maximum epitope length in external evaluation data\n",
    "eval_lengths = [len(seq) for seq in X_seq_eval_raw]\n",
    "max_eval_len = max(eval_lengths)\n",
    "print(\"Maximum epitope length in external eval data:\", max_eval_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Encode sequences ===\n",
    "def blosum_encode_sequence(seq):\n",
    "    return np.array([blosum62.get(aa, [0]*20) for aa in seq])\n",
    "\n",
    "def encode_dataset(seq_list, max_len):\n",
    "    encoded = []\n",
    "    for seq in seq_list:\n",
    "        encoded_seq = blosum_encode_sequence(seq)\n",
    "        pad_width = ((0, max_len - len(seq)), (0, 0))\n",
    "        padded = np.pad(encoded_seq, pad_width, mode='constant')\n",
    "        encoded.append(padded)\n",
    "    return np.array(encoded)\n",
    "\n",
    "max_len = max(len(seq) for seq in X_seq_train_raw)\n",
    "X_train_encoded = encode_dataset(X_seq_train_raw, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoded training shape:\", X_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One encoded epitope shape:\", X_train_encoded[0].shape)\n",
    "print(X_train_encoded[0])  # will show a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245adf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Flatten the 3D array to 2D for SMOTE ===\n",
    "X_train_flat = X_train_encoded.reshape(X_train_encoded.shape[0], -1)  # shape: (225887, 400)\n",
    "\n",
    "print(\"Shape before Borderline-SMOTE:\", X_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Apply BorderlineSMOTE ===\n",
    "borderline_smote = BorderlineSMOTE(kind='borderline-1', random_state=42)\n",
    "X_train_resampled, y_train_resampled = borderline_smote.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "print(\"After Borderline-SMOTE:\", Counter(y_train_resampled))\n",
    "print(\"Shape after Borderline-SMOTE:\", X_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_resampled[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Reshape back to 3D for RNN input ===\n",
    "X_train_balanced = X_train_resampled.reshape(-1, X_train_encoded.shape[1], X_train_encoded.shape[2])  # shape: (samples, 20, 20)\n",
    "\n",
    "print(\"Final balanced input shape:\", X_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a10506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test data using training max_len\n",
    "X_test_encoded = encode_dataset(X_seq_test_raw, max_len)\n",
    "X_eval_encoded = encode_dataset(X_seq_eval_raw, max_len)\n",
    "\n",
    "print(\"Test shape :\", X_test_encoded.shape)\n",
    "print(\"Eval shape :\", X_eval_encoded.shape) # is this 3d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6909bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Model Builder ===\n",
    "def build_model(units=64, dropout_rate=0.3, learning_rate=1e-3, optimizer='adam'):\n",
    "    input_layer = Input(shape=(X_train_balanced.shape[1], X_train_balanced.shape[2]))\n",
    "    x = GRU(units, return_sequences=True)(input_layer)\n",
    "    x = GRU(units)(x)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate) if optimizer.lower() == 'adam' \\\n",
    "        else tf.keras.optimizers.RMSprop(learning_rate)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Grid definition\n",
    "param_grid = {\n",
    "    'units': [16, 32, 64, 128],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'learning_rate': [1e-3, 5e-4],\n",
    "    'optimizer': ['Adam', 'RMSprop'],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "best_params = None\n",
    "\n",
    "# Grid search loop\n",
    "for params in itertools.product(*param_grid.values()):\n",
    "    combo = dict(zip(param_grid.keys(), params))\n",
    "    build_args = {k: v for k, v in combo.items() if k != 'batch_size'}\n",
    "\n",
    "    model = build_model(**build_args)\n",
    "    history = model.fit(\n",
    "        X_train_balanced, y_train_resampled,\n",
    "        epochs=20,\n",
    "        batch_size=combo['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        verbose=2,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    print(f\"Tested combo {combo} â€” max val_accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_params = combo\n",
    "\n",
    "print(\"\\nâœ… Best Hyperparameters Found:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild with best params\n",
    "build_args = {k: v for k, v in best_params.items() if k != 'batch_size'}\n",
    "best_batch_size = best_params['batch_size']\n",
    "final_model = build_model(**build_args)\n",
    "\n",
    "# Retrain on full training data\n",
    "final_model.fit(\n",
    "    X_train_balanced, y_train_resampled,\n",
    "    epochs=300,\n",
    "    batch_size=best_batch_size,\n",
    "    verbose=2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "final_model.save('best_model_gru_blosum.keras')\n",
    "print(\"\\n Final trained model saved as 'best_model_gru_blosum.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# PREDICTION + EVALUATION\n",
    "# ==========================\n",
    "\n",
    "def evaluate_metrics(y_true, y_probs, dataset_name):\n",
    "    y_pred = (y_probs > 0.5).astype(\"int32\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\nðŸ“Š {dataset_name}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"F1 Score    : {f1:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"ROC AUC     : {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# --- Predict on Test and External Validation Sets ---\n",
    "y_test_probs = final_model.predict(X_test_encoded).flatten()\n",
    "y_eval_probs = final_model.predict(X_eval_encoded).flatten()\n",
    "\n",
    "# --- Evaluate ---\n",
    "evaluate_metrics(y_test, y_test_probs, \"Test Set\")\n",
    "evaluate_metrics(y_eval, y_eval_probs, \"External Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 10-FOLD CROSS-VALIDATION ON FINAL MODEL\n",
    "# ==========================\n",
    "\n",
    "print(\"\\nâœ… Performing 10-Fold Cross-Validation on Final Model...\")\n",
    "cv_scores = []\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_balanced, y_train_resampled), 1):\n",
    "    X_train_cv, X_val_cv = X_train_balanced[train_idx], X_train_balanced[val_idx]\n",
    "    y_train_cv, y_val_cv = y_train_resampled[train_idx], y_train_resampled[val_idx]\n",
    "\n",
    "    model_cv = build_model(**build_args)\n",
    "    model_cv.fit(\n",
    "        X_train_cv, y_train_cv,\n",
    "        epochs=30,\n",
    "        batch_size=best_batch_size,\n",
    "        verbose=2,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0)\n",
    "    cv_scores.append(val_acc)\n",
    "    print(f\"Fold {fold}: Validation Accuracy = {val_acc:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… 10-Fold Cross-Validation Complete\")\n",
    "print(\"Fold Accuracies:\", cv_scores)\n",
    "print(\"Mean Validation Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
