{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#File Preparation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first chunk of code takes three csv files generated via Biopython and Pfeature and then retains only the features used in training of XGB-BPred model.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load all CSV files\n",
    "file_A = pd.read_csv(\"Bcell_Biopython.csv\") # Features from Biopython\n",
    "file_B = pd.read_csv(\"Bcell_comp.csv\") # Composition Features from Pfeature\n",
    "file_C = pd.read_csv(\"Bcell_bin.csv\") # Binary Features from Pfeature\n",
    "file_D = pd.read_csv(\"test_B_data.csv\") #test data given in github repository\n",
    "\n",
    "# Step 1: Merge A, B, and C into E\n",
    "# Assuming you want to concatenate rows\n",
    "E = pd.concat([file_A, file_B, file_C], ignore_index=True)\n",
    "\n",
    "# Step 2: Match columns of E with columns in D\n",
    "# Get column names from D\n",
    "columns_in_D = file_D.columns\n",
    "\n",
    "# Retain only columns in E that are present in D\n",
    "E = E[columns_in_D.intersection(E.columns)]\n",
    "\n",
    "# Step 3: Add missing columns with zero values\n",
    "for col in columns_in_D:\n",
    "    if col not in E.columns:\n",
    "        E[col] = 0  # Add missing column and fill with zeros\n",
    "\n",
    "# Step 4: Reorder columns to match the order in D\n",
    "E_final = E[columns_in_D]\n",
    "\n",
    "# Step 5: Save the final E.csv\n",
    "E_final.to_csv(\"Bcell_merged.csv\", index=False)\n",
    "\n",
    "print(\"Bcell_merged.csv has been successfully created with the exact columns from test_B_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #The second chunk of code normalizes the extracted features. Finalized file can be easily employed for prediction purposes.\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Bcell_merged.csv')\n",
    "\n",
    "# Separate the first two columns\n",
    "epitope_label = df.iloc[:, :2]\n",
    "features = df.iloc[:, 2:]\n",
    "\n",
    "# Initialize scalers\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "minmax_scaled = minmax_scaler.fit_transform(features)\n",
    "minmax_scaled_df = pd.DataFrame(minmax_scaled, columns=features.columns)\n",
    "\n",
    "# Combine with epitope and label columns\n",
    "standard_scaled_final = pd.concat([epitope_label, standard_scaled_df], axis=1)\n",
    "minmax_scaled_final = pd.concat([epitope_label, minmax_scaled_df], axis=1)\n",
    "\n",
    "# Save the normalized datasets\n",
    "minmax_scaled_final.to_csv('Epitopes_scaled.csv', index=False)\n",
    "\n",
    "# Display the first few rows of both normalized datasets\n",
    "print(\"\\\n",
    "First few rows of MinMaxScaler normalized data:\")\n",
    "print(minmax_scaled_final.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
