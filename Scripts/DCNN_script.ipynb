{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras==3.2.0 tensorflow-intel==2.17.0 scikeras==0.13.0\n",
    "!pip show keras tensorflow-intel scikeras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show keras\n",
    "import sklearn\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "train_data = pd.read_csv(\"train_Boarderline_smote_B_data.csv\")\n",
    "\n",
    "# Inspect the first few rows of your dataset\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extract epitope sequences (first column)\n",
    "sequences = train_data.iloc[:, 0].values\n",
    "\n",
    "# Use LabelEncoder to convert sequences into integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "X_seq = label_encoder.fit_transform(sequences)  # Convert sequences to integers\n",
    "\n",
    "# Verify the encoding\n",
    "print(f\"First 10 Encoded Sequences: {X_seq[:10]}\")\n",
    "print(f\"Number of Unique Sequences: {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape integer-encoded sequences for compatibility\n",
    "X_seq = X_seq.reshape(-1, 1)\n",
    "\n",
    "# Extract numeric features (columns 3 onward)\n",
    "X_numeric = train_data.iloc[:, 2:].values\n",
    "\n",
    "# Combine sequence integers and numeric features\n",
    "import numpy as np\n",
    "X_combined = np.hstack((X_seq, X_numeric))\n",
    "\n",
    "# Check combined data shape\n",
    "print(f\"Combined feature shape: {X_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(\"train_Boarderline_smote_B_data.csv\")\n",
    "test_data = pd.read_csv(\"test_B_data.csv\")\n",
    "eval_data = pd.read_csv(\"external_eval_B_data.csv\")\n",
    "\n",
    "# Inspect the datasets\n",
    "print(f\"Train Data Shape: {train_data.shape}\")\n",
    "print(f\"Test Data Shape: {test_data.shape}\")\n",
    "print(f\"Evaluation Data Shape: {eval_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Preprocess the Data, Encode Epitope Sequences, Convert the sequences in the first column of each dataset into integers using LabelEncoder:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all sequences from train, test, and eval\n",
    "all_sequences = pd.concat([train_data.iloc[:, 0], test_data.iloc[:, 0], eval_data.iloc[:, 0]])\n",
    "\n",
    "# Fit LabelEncoder on all unique sequences\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_sequences)\n",
    "\n",
    "# Transform sequences in all datasets\n",
    "X_train_seq = label_encoder.transform(train_data.iloc[:, 0])  # Train sequences\n",
    "X_test_seq = label_encoder.transform(test_data.iloc[:, 0])    # Test sequences\n",
    "X_eval_seq = label_encoder.transform(eval_data.iloc[:, 0])    # Eval sequences\n",
    "\n",
    "# Verify encoding\n",
    "print(f\"Number of unique sequences (vocabulary size): {len(label_encoder.classes_)}\")\n",
    "\n",
    "##Combine Encoded Features with Numeric Features\n",
    "import numpy as np\n",
    "# Reshape sequence encodings for concatenation\n",
    "X_train_seq = X_train_seq.reshape(-1, 1)\n",
    "X_test_seq = X_test_seq.reshape(-1, 1)\n",
    "X_eval_seq = X_eval_seq.reshape(-1, 1)\n",
    "\n",
    "# Extract numeric features (columns 3 onward) from each dataset\n",
    "X_train_numeric = train_data.iloc[:, 2:].values\n",
    "X_test_numeric = test_data.iloc[:, 2:].values\n",
    "X_eval_numeric = eval_data.iloc[:, 2:].values\n",
    "\n",
    "# Combine sequence encodings and numeric features\n",
    "X_train = np.hstack((X_train_seq, X_train_numeric))\n",
    "X_test = np.hstack((X_test_seq, X_test_numeric))\n",
    "X_eval = np.hstack((X_eval_seq, X_eval_numeric))\n",
    "\n",
    "print(f\"Train Feature Shape: {X_train.shape}\")\n",
    "print(f\"Test Feature Shape: {X_test.shape}\")\n",
    "print(f\"Eval Feature Shape: {X_eval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 1: Define the Model Function for Hyperparameter Tuning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(learning_rate=0.001, filters=32, kernel_size=3, dense_units=128, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=50, input_length=1),  # Embedding Layer\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(2, activation='softmax')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure this code has been run before grid search:\n",
    "# Combine sequence encoding and numeric features\n",
    "X_train = np.hstack((X_train_seq.reshape(-1, 1), train_data.iloc[:, 2:].values))\n",
    "\n",
    "# Use integer labels (0 or 1) for y_train\n",
    "y_train = train_data.iloc[:, 1].values  # Labels in binary form (not categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify create model function\n",
    "def create_model(vocab_size, learning_rate=0.001, filters=32, kernel_size=3, dense_units=128, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=50, input_length=1),  # Embedding Layer\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(2, activation='softmax')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "#Step 2: Pass vocab_size in KerasClassifier\n",
    "vocab_size = len(label_encoder.classes_)  # Ensure this is defined\n",
    "\n",
    "keras_clf = KerasClassifier(model=create_model, model__vocab_size=vocab_size, epochs=10, batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.001, 0.01],\n",
    "    'model__filters': [32, 64],\n",
    "    'model__kernel_size': [3, 5],\n",
    "    'model__dense_units': [128, 256],\n",
    "    'model__dropout_rate': [0.3, 0.5],\n",
    "    'batch_size': [32, 64],  # Training parameter\n",
    "    'epochs': [20]  # Training parameter\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=keras_clf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps to Use Preprocessed Data with Simple DCNN\n",
    "#model 1\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(767, 1)),  # Conv1D expects 3D input\n",
    "    MaxPooling1D(pool_size=2),  # Reduce dimensionality\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),  # Another Conv1D layer\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),  # Flatten to feed into Dense layers\n",
    "    Dense(128, activation='relu'),  # Fully connected layer\n",
    "    Dropout(0.3),  # Regularization\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # Binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")  # Should be (448826, 767)\n",
    "print(f\"X_train total size: {X_train.size}\")  # Should be 448826 * 767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sequence and numeric features\n",
    "print(f\"X_train_seq shape: {X_train_seq.shape}\")  # Expected (448826, 1)\n",
    "print(f\"X_train_numeric shape: {X_train_numeric.shape}\")  # Expected (448826, 766)\n",
    "\n",
    "# Combine sequence and numeric features\n",
    "X_train = np.hstack((X_train_seq, X_train_numeric))\n",
    "X_test = np.hstack((X_test_seq, X_test_numeric))\n",
    "X_eval = np.hstack((X_eval_seq, X_eval_numeric))\n",
    "\n",
    "print(f\"Combined X_train shape: {X_train.shape}\")  # Should be (448826, 767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for Conv1D\n",
    "X_train = X_train.reshape(-1, 767, 1)  # Each sample has 767 timesteps, 1 feature per timestep\n",
    "X_test = X_test.reshape(-1, 767, 1)\n",
    "X_eval = X_eval.reshape(-1, 767, 1)\n",
    "\n",
    "print(f\"Reshaped X_train shape: {X_train.shape}\")  # Should be (448826, 767, 1)\n",
    "print(f\"Reshaped X_test shape: {X_test.shape}\")    # Should be (83649, 767, 1)\n",
    "print(f\"Reshaped X_eval shape: {X_eval.shape}\")    # Should be (83649, 767, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels (second column) from each dataset\n",
    "y_train = train_data.iloc[:, 1].values  # Binary labels for train data\n",
    "y_test = test_data.iloc[:, 1].values    # Binary labels for test data\n",
    "y_eval = eval_data.iloc[:, 1].values    # Binary labels for eval data\n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"y_eval shape: {y_eval.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate on external evaluation data\n",
    "eval_loss, eval_accuracy = model.evaluate(X_eval, y_eval, verbose=0)\n",
    "print(f\"External Validation Accuracy: {eval_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(767, 1)),  # Conv1D expects 3D input\n",
    "    MaxPooling1D(pool_size=2),  # Reduce dimensionality\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),  # Another Conv1D layer\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),  # Flatten to feed into Dense layers\n",
    "    Dense(128, activation='relu'),  # Fully connected layer\n",
    "    Dropout(0.3),  # Regularization\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),  # Regularization\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # Binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Check sequence and numeric features\n",
    "print(f\"X_train_seq shape: {X_train_seq.shape}\")  # Expected (448826, 1)\n",
    "print(f\"X_train_numeric shape: {X_train_numeric.shape}\")  # Expected (448826, 766)\n",
    "\n",
    "# Combine sequence and numeric features\n",
    "X_train = np.hstack((X_train_seq, X_train_numeric))\n",
    "X_test = np.hstack((X_test_seq, X_test_numeric))\n",
    "X_eval = np.hstack((X_eval_seq, X_eval_numeric))\n",
    "\n",
    "print(f\"Combined X_train shape: {X_train.shape}\")  # Should be (448826, 767)\n",
    "# Reshape data for Conv1D\n",
    "X_train = X_train.reshape(-1, 767, 1)  # Each sample has 767 timesteps, 1 feature per timestep\n",
    "X_test = X_test.reshape(-1, 767, 1)\n",
    "X_eval = X_eval.reshape(-1, 767, 1)\n",
    "\n",
    "print(f\"Reshaped X_train shape: {X_train.shape}\")  # Should be (448826, 767, 1)\n",
    "print(f\"Reshaped X_test shape: {X_test.shape}\")    # Should be (83649, 767, 1)\n",
    "print(f\"Reshaped X_eval shape: {X_eval.shape}\")    # Should be (83649, 767, 1)\n",
    "\n",
    "# Extract labels (second column) from each dataset\n",
    "y_train = train_data.iloc[:, 1].values  # Binary labels for train data\n",
    "y_test = test_data.iloc[:, 1].values    # Binary labels for test data\n",
    "y_eval = eval_data.iloc[:, 1].values    # Binary labels for eval data\n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"y_eval shape: {y_eval.shape}\")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate on external evaluation data\n",
    "eval_loss, eval_accuracy = model.evaluate(X_eval, y_eval, verbose=0)\n",
    "print(f\"External Validation Accuracy: {eval_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model in HDF5 format\n",
    "model.save(\"dcnn_epitope_classifier_bcell_model2.h5\")\n",
    "print(\"Model saved as 'dcnn_epitope_classifier_bcell_model2.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate binary predictions\n",
    "y_test_pred = (model.predict(X_test) > 0.5).astype(int).ravel()\n",
    "y_eval_pred = (model.predict(X_eval) > 0.5).astype(int).ravel()\n",
    "\n",
    "# Confusion matrices\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "tn_eval, fp_eval, fn_eval, tp_eval = confusion_matrix(y_eval, y_eval_pred).ravel()\n",
    "\n",
    "# Sensitivity and Specificity calculations for Test Set\n",
    "sensitivity_test = tp_test / (tp_test + fn_test)\n",
    "specificity_test = tn_test / (tn_test + fp_test)\n",
    "print(f\"Test Sensitivity: {sensitivity_test:.2f}\")\n",
    "print(f\"Test Specificity: {specificity_test:.2f}\")\n",
    "\n",
    "# Sensitivity and Specificity calculations for Validation Set\n",
    "sensitivity_eval = tp_eval / (tp_eval + fn_eval)\n",
    "specificity_eval = tn_eval / (tn_eval + fp_eval)\n",
    "print(f\"Validation Sensitivity: {sensitivity_eval:.2f}\")\n",
    "print(f\"Validation Specificity: {specificity_eval:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classification report for Test Set\n",
    "print(\"\\nTest Data - Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Classification report for Validation Set\n",
    "print(\"\\nValidation Data - Classification Report:\")\n",
    "print(classification_report(y_eval, y_eval_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities for ROC curve\n",
    "y_test_prob = model.predict(X_test).ravel()  # Test probabilities\n",
    "y_eval_prob = model.predict(X_eval).ravel()  # Validation probabilities\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "fpr_eval, tpr_eval, thresholds_eval = roc_curve(y_eval, y_eval_prob)\n",
    "roc_auc_eval = auc(fpr_eval, tpr_eval)\n",
    "\n",
    "# Print the values\n",
    "print(\"Test Data - ROC Curve Values\")\n",
    "print(\"False Positive Rate (FPR):\", fpr_test)\n",
    "print(\"True Positive Rate (TPR):\", tpr_test)\n",
    "print(\"Thresholds:\", thresholds_test)\n",
    "print(f\"ROC AUC: {roc_auc_test:.2f}\\n\")\n",
    "\n",
    "print(\"Validation Data - ROC Curve Values\")\n",
    "print(\"False Positive Rate (FPR):\", fpr_eval)\n",
    "print(\"True Positive Rate (TPR):\", tpr_eval)\n",
    "print(\"Thresholds:\", thresholds_eval)\n",
    "print(f\"ROC AUC: {roc_auc_eval:.2f}\\n\")\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Test ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label=f'ROC AUC = {roc_auc_test:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--', label='Random Classifier (AUC = 0.50)')\n",
    "plt.title('Test Data - ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Validation ROC Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr_eval, tpr_eval, color='green', lw=2, label=f'ROC AUC = {roc_auc_eval:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--', label='Random Classifier (AUC = 0.50)')\n",
    "plt.title('Validation Data - ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_validation_roc_auc_bcell.png\", dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Test Data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# External Validation Data\n",
    "fpr_eval, tpr_eval, _ = roc_curve(y_eval, y_eval_prob)\n",
    "roc_auc_eval = auc(fpr_eval, tpr_eval)\n",
    "\n",
    "print(f\"Test ROC AUC: {roc_auc_test:.2f}\")\n",
    "print(f\"External Validation ROC AUC: {roc_auc_eval:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix for test data\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "# Confusion matrix for evaluation data\n",
    "tn_eval, fp_eval, fn_eval, tp_eval = confusion_matrix(y_eval, y_eval_pred).ravel()\n",
    "\n",
    "# Print the confusion matrices to verify\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(f\"TN: {tn_test}, FP: {fp_test}, FN: {fn_test}, TP: {tp_test}\")\n",
    "\n",
    "print(\"\\nExternal Validation Confusion Matrix:\")\n",
    "print(f\"TN: {tn_eval}, FP: {fp_eval}, FN: {fn_eval}, TP: {tp_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_test = tp_test / (tp_test + fn_test)\n",
    "specificity_test = tn_test / (tn_test + fp_test)\n",
    "\n",
    "print(f\"Test Sensitivity: {sensitivity_test:.2f}\")\n",
    "print(f\"Test Specificity: {specificity_test:.2f}\")\n",
    "\n",
    "sensitivity_eval = tp_eval / (tp_eval + fn_eval)\n",
    "specificity_eval = tn_eval / (tn_eval + fp_eval)\n",
    "\n",
    "print(f\"External Validation Sensitivity: {sensitivity_eval:.2f}\")\n",
    "print(f\"External Validation Specificity: {specificity_eval:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics\n",
    "accuracies = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Cross-validation loop\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(f\"Training fold {i+1}...\")\n",
    "    \n",
    "    # Clone the model for each fold to avoid state sharing\n",
    "    fold_model = clone_model(model)\n",
    "    fold_model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                       loss='binary_crossentropy', \n",
    "                       metrics=['accuracy'])\n",
    "    \n",
    "    # Train on the training fold\n",
    "    fold_model.fit(X_train[train_idx], y_train[train_idx], epochs=20, batch_size=64, verbose=0)\n",
    "    \n",
    "    # Evaluate on the test fold\n",
    "    y_prob = fold_model.predict(X_train[test_idx]).ravel()\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_train[test_idx], y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_train[test_idx], y_prob)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label=f'Fold {i+1} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, label=f'Mean ROC (AUC = {mean_auc:.2f})', lw=2)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for 10-Fold Cross-Validation')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"cv_roc_curve_dcnn_bcell.png\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "# Print mean accuracy and AUC\n",
    "print(f\"Mean 10-Fold Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-validation accuracies to a text file\n",
    "with open('cv_accuracies_dcnn.txt', 'w') as f:\n",
    "    f.write(\"Cross-Validation Accuracies for each fold:\\n\")\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        f.write(f\"Fold {i+1} Accuracy: {acc:.4f}\\n\")\n",
    "    f.write(f\"\\nMean 10-Fold Accuracy: {np.mean(accuracies):.4f}\\n\")\n",
    "\n",
    "print(\"Accuracy of each fold has been saved to 'cv_accuracies_dcnn_bcell.txt'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
