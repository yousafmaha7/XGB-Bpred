{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec73b9cf",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the file: `B cell 1.xlsx`\n",
    "\n",
    "# Load the Excel file and remove rows where the epitope species is human or Homo sapiens\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = 'B cell 1.xlsx'\n",
    "dataframes = pd.read_excel(file_path, sheet_name=None, engine='calamine')\n",
    "\n",
    "# Process each sheet and remove rows with human or Homo sapiens\n",
    "for sheet_name, df in dataframes.items():\n",
    "    # Filter out rows where 'Epitope Species' is 'human' or 'Homo sapiens'\n",
    "    df_filtered = df[~df['Epitope Species'].str.lower().isin(['human', 'homo sapiens'])]\n",
    "    dataframes[sheet_name] = df_filtered\n",
    "\n",
    "# Save the filtered data back to a new Excel file\n",
    "output_file = 'B_cell_1_filtered.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in dataframes.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print('Filtered data saved to', output_file)\" run this code to remove all epitopes whose epitope specie is human or homo sapiens. also provide list of epitopes which were present initially , how many removed and how many epitopes are still present in new file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249f279",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "I'll help you analyze this. Let's break it down into steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original file and get initial counts\n",
    "import pandas as pd\n",
    "\n",
    "# Load original file\n",
    "df_original = pd.read_excel('B cell 1.xlsx', engine='calamine')\n",
    "\n",
    "# Store initial count\n",
    "initial_count = len(df_original)\n",
    "\n",
    "# Get list of all original epitopes\n",
    "print(\"Initial Epitopes:\")\n",
    "print(df_original['Epitope Name'].tolist())\n",
    "print(\"\\nTotal initial epitopes:\", initial_count)\n",
    "\n",
    "# Filter out human/Homo sapiens\n",
    "df_filtered = df_original[~df_original['Epitope Species'].str.lower().isin(['human', 'homo sapiens'])]\n",
    "\n",
    "# Save filtered data\n",
    "df_filtered.to_excel('B_cell_1_filtered.xlsx', index=False)\n",
    "\n",
    "# Get counts of removed and remaining\n",
    "removed_count = initial_count - len(df_filtered)\n",
    "remaining_count = len(df_filtered)\n",
    "\n",
    "print(\"\\nNumber of epitopes removed:\", removed_count)\n",
    "print(\"Number of epitopes remaining:\", remaining_count)\n",
    "\n",
    "print(\"\\nRemaining Epitopes:\")\n",
    "print(df_filtered['Epitope Name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b9a6a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "Based on the analysis:\n",
    "\n",
    "- Total initial epitopes: 707,608\n",
    "- Number of epitopes removed: 286\n",
    "- Number of epitopes remaining: 707,322\n",
    "\n",
    "The filtered data has been saved to 'B_cell_1_filtered.xlsx'. Due to the large number of epitopes, the complete lists were too large to display, but the filtering process successfully removed all human/Homo sapiens entries while preserving the vast majority of the data (99.96% of entries were retained).\n",
    "\n",
    "You can download the filtered file at https://julius.ai/files/B_cell_1_filtered.xlsx\n",
    "\n",
    "Would you like to see a sample of the removed epitopes or any specific analysis of the remaining data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155f0d4",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "I uploaded the file: `paste.txt`\n",
    "\n",
    "please provide how many epitopes are filtered at each step.. so that i can understand . now please look at three columns.. first column of epitope, second column of Assay mETHOD AND THIRD Assay qualitative measure.. is there any epitope that shows positive in one assay and negative in another.. means inconsistent values.. how many epitopes are showing consistent results... use the following commands \" at every step use the file that is newly created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edee0ea",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "I will first load the newly created filtered file (`B_cell_1_filtered.xlsx`) and analyze the three specified columns to check for epitopes with inconsistent assay qualitative measures (positive in one assay and negative in another). Then, I will count how many epitopes show consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ed4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered file\n",
    "filtered_file = 'B_cell_1_filtered.xlsx'\n",
    "df_filtered = pd.read_excel(filtered_file, engine='openpyxl')\n",
    "\n",
    "# Check for inconsistent assay qualitative measures\n",
    "# Group by 'Epitope Name' and check if there are both 'Positive' and 'Negative' values in 'Assay Qualitative Measure'\n",
    "inconsistent_epitopes = df_filtered.groupby('Epitope Name')['Assay Qualitative Measure'].apply(lambda x: set(x)).apply(lambda x: 'Positive' in x and 'Negative' in x)\n",
    "\n",
    "# Count inconsistent and consistent epitopes\n",
    "inconsistent_count = inconsistent_epitopes.sum()\n",
    "consistent_count = len(inconsistent_epitopes) - inconsistent_count\n",
    "\n",
    "# Get the list of inconsistent epitopes\n",
    "inconsistent_epitopes_list = inconsistent_epitopes[inconsistent_epitopes].index.tolist()\n",
    "\n",
    "print(\"Number of inconsistent epitopes:\", inconsistent_count)\n",
    "print(\"Number of consistent epitopes:\", consistent_count)\n",
    "print(\"\\nList of inconsistent epitopes:\")\n",
    "print(inconsistent_epitopes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211b968",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The analysis successfully identified epitopes with inconsistent assay qualitative measures, showing 42,551 inconsistent epitopes and 383,027 consistent ones. I will now summarize the results and provide further insights if needed.\n",
    "- **Number of inconsistent epitopes**: 42,551  \n",
    "- **Number of consistent epitopes**: 383,027  \n",
    "\n",
    "The inconsistent epitopes are those that show both \"Positive\" and \"Negative\" assay qualitative measures across different assays. The consistent epitopes have uniform results. If you'd like, I can provide a detailed breakdown or save the inconsistent epitopes to a file for further review. Let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160b49a",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "save consistent epitopes in new excel. how many types of entries are in Assay Qualitative Measure  in consistent epitope file? replace all Positive-Low, Positive-Intermediate, and Positive-High values with Positive in Assay Qualitative measure column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered file\n",
    "df_filtered = pd.read_excel('B_cell_1_filtered.xlsx')\n",
    "\n",
    "# Get consistent epitopes\n",
    "consistent_epitopes = df_filtered.groupby('Epitope Name')['Assay Qualitative Measure'].apply(lambda x: set(x)).apply(lambda x: not ('Positive' in x and 'Negative' in x))\n",
    "consistent_epitopes = consistent_epitopes[consistent_epitopes].index.tolist()\n",
    "\n",
    "# Filter dataframe to keep only consistent epitopes\n",
    "df_consistent = df_filtered[df_filtered['Epitope Name'].isin(consistent_epitopes)]\n",
    "\n",
    "# Show unique values in Assay Qualitative Measure before replacement\n",
    "print(\"Unique values in Assay Qualitative Measure before replacement:\")\n",
    "print(df_consistent['Assay Qualitative Measure'].unique())\n",
    "\n",
    "# Replace Positive variants with just 'Positive'\n",
    "df_consistent['Assay Qualitative Measure'] = df_consistent['Assay Qualitative Measure'].replace({\n",
    "    'Positive-Low': 'Positive',\n",
    "    'Positive-Intermediate': 'Positive',\n",
    "    'Positive-High': 'Positive'\n",
    "})\n",
    "\n",
    "print(\"\\nUnique values in Assay Qualitative Measure after replacement:\")\n",
    "print(df_consistent['Assay Qualitative Measure'].unique())\n",
    "\n",
    "# Save to new excel file\n",
    "output_file = 'consistent_epitopes.xlsx'\n",
    "df_consistent.to_excel(output_file, index=False)\n",
    "print(f\"\\nSaved consistent epitopes to {output_file}\")\n",
    "\n",
    "# Count frequency of each value\n",
    "value_counts = df_consistent['Assay Qualitative Measure'].value_counts()\n",
    "print(\"\\nFrequency of each value:\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e674318",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The process successfully identified unique values in the \"Assay Qualitative Measure\" column, replaced all \"Positive-Low,\" \"Positive-Intermediate,\" and \"Positive-High\" with \"Positive,\" and saved the consistent epitopes to a new file. Below are the results:\n",
    "\n",
    "- **Unique values before replacement**: {outputs_dict[\"db237a58\"]}\n",
    "- **Unique values after replacement**: {outputs_dict[\"ff90325d\"]}\n",
    "- **Frequency of each value**: {outputs_dict[\"6cdec8f5\"]}\n",
    "\n",
    "The consistent epitopes have been saved to `consistent_epitopes.xlsx`. You can download it at https://julius.ai/files/consistent_epitopes.xlsx. Let me know if further analysis is needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa3a34",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "now in consistent_epitopes.xlsx, remove all epitopes data with non-natural amino acids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb3c06",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "I'll help remove epitopes containing non-natural amino acids. First, let's identify and remove epitopes that contain characters other than the 20 standard amino acids (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the consistent epitopes file\n",
    "df = pd.read_excel('consistent_epitopes.xlsx')\n",
    "\n",
    "# Define the 20 standard amino acids\n",
    "standard_aa = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "\n",
    "# Function to check if sequence contains only natural amino acids\n",
    "def contains_only_natural_aa(sequence):\n",
    "    try:\n",
    "        return set(str(sequence).upper()).issubset(standard_aa)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Get initial count\n",
    "initial_count = len(df)\n",
    "\n",
    "# Filter to keep only sequences with natural amino acids\n",
    "df_natural = df[df['Epitope Name'].apply(contains_only_natural_aa)]\n",
    "\n",
    "# Get final count\n",
    "final_count = len(df_natural)\n",
    "\n",
    "# Save to new file\n",
    "output_file = 'consistent_natural_epitopes.xlsx'\n",
    "df_natural.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Initial number of epitopes: {initial_count}\")\n",
    "print(f\"Number of epitopes removed: {initial_count - final_count}\")\n",
    "print(f\"Final number of epitopes: {final_count}\")\n",
    "\n",
    "# Show some examples of removed epitopes\n",
    "removed_df = df[~df['Epitope Name'].apply(contains_only_natural_aa)]\n",
    "print(\"\\nExamples of removed epitopes (first 10):\")\n",
    "print(removed_df['Epitope Name'].head(10).tolist())\n",
    "\n",
    "# Count frequency of Assay Qualitative Measure in final dataset\n",
    "print(\"\\nFrequency of Assay Qualitative Measure in final dataset:\")\n",
    "print(df_natural['Assay Qualitative Measure'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972a4a3",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The process successfully filtered out epitopes containing non-natural amino acids, reducing the dataset by 1,058 entries. The final dataset contains 560,592 epitopes, and the updated file has been saved. Below are the results:\n",
    "\n",
    "- **Initial number of epitopes**: {outputs_dict[\"ac1202f0\"]}\n",
    "- **Number of epitopes removed**: {outputs_dict[\"6396ff8d\"]}\n",
    "- **Final number of epitopes**: {outputs_dict[\"23e1455e\"]}\n",
    "- **Examples of removed epitopes**: {outputs_dict[\"063e60b1\"]}\n",
    "- **Frequency of Assay Qualitative Measure in final dataset**: {outputs_dict[\"a2793d25\"]}\n",
    "\n",
    "The updated file is available for download at https://julius.ai/files/consistent_natural_epitopes.xlsx. Let me know if further analysis is needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc471a",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "is there any redundancy in this consistent_natural_epitope file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the consistent natural epitopes file\n",
    "df = pd.read_excel('consistent_natural_epitopes.xlsx')\n",
    "\n",
    "# Check for duplicate epitopes\n",
    "duplicate_epitopes = df[df.duplicated(subset=['Epitope Name'], keep=False)]\n",
    "unique_duplicate_epitopes = duplicate_epitopes['Epitope Name'].unique()\n",
    "\n",
    "# Count total unique epitopes\n",
    "total_rows = len(df)\n",
    "unique_epitopes = len(df['Epitope Name'].unique())\n",
    "duplicate_count = len(unique_duplicate_epitopes)\n",
    "\n",
    "print(f\"Total rows in dataset: {total_rows}\")\n",
    "print(f\"Number of unique epitopes: {unique_epitopes}\")\n",
    "print(f\"Number of epitopes with duplicates: {duplicate_count}\")\n",
    "\n",
    "# Show example of duplicates with their counts and assay measures\n",
    "if len(unique_duplicate_epitopes) > 0:\n",
    "    print(\"\\nExample of first 5 duplicate epitopes and their details:\")\n",
    "    for epitope in unique_duplicate_epitopes[:5]:\n",
    "        subset = df[df['Epitope Name'] == epitope]\n",
    "        print(f\"\\nEpitope: {epitope}\")\n",
    "        print(f\"Number of occurrences: {len(subset)}\")\n",
    "        print(\"Assay Methods used:\")\n",
    "        print(subset['Assay Method'].value_counts())\n",
    "        print(\"Qualitative Measures:\")\n",
    "        print(subset['Assay Qualitative Measure'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f532",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "\n",
    "\n",
    "Yes, there is significant redundancy in the dataset. Here's the analysis:\n",
    "\n",
    "{outputs_dict[\"52afa404\"]}\n",
    "{outputs_dict[\"24f8801d\"]}\n",
    "{outputs_dict[\"f1a7b0a8\"]}\n",
    "\n",
    "Looking at some examples of duplicates:\n",
    "\n",
    "1. Epitope \"SETNKNPTSHSNSTTTSLNNN\":\n",
    "- Occurs 2 times\n",
    "- Different assay methods: {outputs_dict[\"5ffbe1b8\"]}\n",
    "- All instances are {outputs_dict[\"0b03ba2d\"]}\n",
    "\n",
    "2. Epitope \"NQQSRWGLGSPNCHGPDWASPVCQRHS\":\n",
    "- Occurs 3 times\n",
    "- Different assay methods: {outputs_dict[\"5ae8ccc2\"]}\n",
    "- All instances are {outputs_dict[\"a0c5428d\"]}\n",
    "\n",
    "The redundancy appears to be mainly due to the same epitopes being tested with different assay methods. Would you like me to create a non-redundant version of the file that consolidates these entries, or would you prefer to keep the multiple entries to preserve the information about different assay methods used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5a10d",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "is there any redundant epitope entry in consistent_natural_epitopes.xlsx. if yes, please remove all redundant epitopes data and save them in a file name unique_epitopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2fe84d",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Let me check for exact duplicate rows (completely identical entries) and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b13bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the consistent natural epitopes file\n",
    "df = pd.read_excel('consistent_natural_epitopes.xlsx')\n",
    "\n",
    "# Get initial count\n",
    "initial_count = len(df)\n",
    "\n",
    "# Check for completely identical rows\n",
    "duplicate_mask = df.duplicated(keep=False)\n",
    "duplicates = df[duplicate_mask]\n",
    "\n",
    "# Remove duplicates keeping first occurrence\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "# Get final count\n",
    "final_count = len(df_unique)\n",
    "\n",
    "print(f\"Initial number of rows: {initial_count}\")\n",
    "print(f\"Number of duplicate rows removed: {initial_count - final_count}\")\n",
    "print(f\"Final number of unique rows: {final_count}\")\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(\"\\nExample of first 5 completely identical duplicate entries:\")\n",
    "    print(duplicates.head())\n",
    "    \n",
    "    # Save unique entries to new file\n",
    "    df_unique.to_excel('unique_epitopes.xlsx', index=False)\n",
    "    print(\"\\nSaved unique entries to unique_epitopes.xlsx\")\n",
    "else:\n",
    "    print(\"\\nNo completely identical duplicate entries found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3308a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The dataset contained 175,642 completely identical duplicate rows, which were removed, leaving 384,950 unique rows. The unique entries have been saved to `unique_epitopes.xlsx`. Below are the details:\n",
    "\n",
    "- {outputs_dict[\"3635880c\"]}\n",
    "- {outputs_dict[\"1617e739\"]}\n",
    "- {outputs_dict[\"9e0bc79a\"]}\n",
    "- {outputs_dict[\"d36158a1\"]}\n",
    "\n",
    "The file is available for download at https://julius.ai/files/unique_epitopes.xlsx. Let me know if further assistance is needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cecc5c1",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "now please remove data of all those epitopes with length less than 4 and more than 20 amino acids and save the resultant file with new name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f5432",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The reasoning is to filter out epitopes that are either too short (less than 4 amino acids) or too long (more than 20 amino acids), as these may not be biologically relevant or consistent with the desired range. I will apply this filter and save the resultant file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed421fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unique epitopes file\n",
    "df = pd.read_excel('unique_epitopes.xlsx')\n",
    "\n",
    "# Filter epitopes based on length (4 to 20 amino acids inclusive)\n",
    "df_filtered = df[df['Epitope Name'].str.len().between(4, 20)]\n",
    "\n",
    "# Get initial and final counts\n",
    "initial_count = len(df)\n",
    "final_count = len(df_filtered)\n",
    "\n",
    "# Save the filtered data to a new file\n",
    "output_file = 'filtered_epitopes.xlsx'\n",
    "df_filtered.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Initial number of rows: {initial_count}\")\n",
    "print(f\"Number of rows removed: {initial_count - final_count}\")\n",
    "print(f\"Final number of rows: {final_count}\")\n",
    "print(\"\\nSaved filtered data to filtered_epitopes.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81554efe",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The filtering process successfully removed epitopes with lengths less than 4 or greater than 20 amino acids. Below are the results:\n",
    "\n",
    "- {outputs_dict[\"0b9eda90\"]}\n",
    "- {outputs_dict[\"e5acbb9e\"]}\n",
    "- {outputs_dict[\"4a1381c1\"]}\n",
    "- {outputs_dict[\"5dc18c59\"]}\n",
    "\n",
    "The filtered data has been saved to `filtered_epitopes.xlsx`. You can download it at https://julius.ai/files/filtered_epitopes.xlsx. Let me know if further assistance is needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541bfc80",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "rename the file as length_filtered epitopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd857f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the file\n",
    "import os\n",
    "\n",
    "old_name = 'filtered_epitopes.xlsx'\n",
    "new_name = 'length_filtered_epitopes.xlsx'\n",
    "\n",
    "# Check if old file exists and rename it\n",
    "if os.path.exists(old_name):\n",
    "    os.rename(old_name, new_name)\n",
    "    print(f\"File renamed from {old_name} to {new_name}\")\n",
    "    \n",
    "    # Verify the number of entries in renamed file\n",
    "    df = pd.read_excel(new_name)\n",
    "    print(f\"\\nVerified: File contains {len(df)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fafdc",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The file was successfully renamed to `length_filtered_epitopes.xlsx`, and its contents were verified to include 380,842 entries. The file is ready for download at https://julius.ai/files/length_filtered_epitopes.xlsx. Let me know if further assistance is needed!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}